use std::fmt;

use crate::file::FileCtx;
use crate::lexer::rt;
use crate::lexer::rt::Kind;
use crate::lexer::spec::Lexeme;
use crate::lexer::spec::Spec;
use crate::report::ReportCtx;
use crate::token::Ident;
use crate::token::Number;
use crate::token::Quoted;
use crate::token::Token;

#[cfg(doc)]
use crate::file::FileMut;

/// A tree-like stream of tokens generated by [`FileMut::lex()`].
#[derive(Clone)]
pub struct TokenStream<'spec> {
  pub(crate) spec: &'spec Spec,
  pub(crate) toks: Vec<rt::Token>,
}

impl<'spec> TokenStream<'spec> {
  pub fn cursor(&self) -> Cursor {
    Cursor {
      spec: self.spec,
      toks: &self.toks,
      cursor: 0,
    }
  }
}

/// A cursor over a piece of a `TokenStream`.
///
/// This type is an iterator that yields [`Token`]s, but it can also be queried
/// for more specific token kinds.
#[derive(Copy, Clone)]
pub struct Cursor<'lex> {
  spec: &'lex Spec,
  toks: &'lex [rt::Token],
  cursor: usize,
}

impl<'lex> Cursor<'lex> {
  /// Returns whether this cursor has yielded all of its tokens.
  pub fn is_empty(&self) -> bool {
    self.cursor >= self.toks.len()
  }

  /// Returns the next token under the cursor without consuming it.
  pub fn peek(&self) -> Option<Token<'lex>> {
    let mut copy = *self;
    copy.next()
  }

  /// Backs up the cursor `count` tokens.
  ///
  /// # Panics
  ///
  /// Panics if this causes the internal cursor to underflow.
  pub fn back_up(&mut self, count: usize) {
    for _ in 0..count {
      assert!(self.cursor > 0, "cursor underflowed");
      self.cursor -= 1;

      if let Kind::Close { offset_to_open, .. } = &self.toks[self.cursor].kind {
        self.cursor -= *offset_to_open as usize;
      }
    }
  }

  /// Takes the next token, if it matches any of the given matchers.
  ///
  /// Otherwise, returns `None`.
  pub fn take_if_matches(&mut self, lexemes: &[Lexeme]) -> Option<Token<'lex>> {
    let next = self.next()?;

    for &lex in lexemes {
      if next.is(lex) {
        return Some(next);
      }
    }

    self.back_up(1);
    None
  }

  /// Takes a `sep`-separated list, calling `element` at the start of each
  /// element.
  ///
  /// This function will continue consuming `sep`-separated elements until
  /// `element` returns `false` or it does not see a separator after `element`.
  ///
  /// This function allows a trailing separator.
  pub fn take_list<T>(
    &mut self,
    sep: Lexeme,
    mut element: impl FnMut(&mut Self) -> Option<T>,
  ) -> Vec<T> {
    let mut prev = None;
    let mut vec = Vec::new();
    while let Some(next) = element(self) {
      assert!(
        prev.replace(self.cursor) != Some(self.cursor),
        "callback to Cursor::take_list failed to make progress",
      );

      vec.push(next);

      if self.take_if_matches(&[sep]).is_none() {
        break;
      }
    }
    vec
  }

  /// Matches the next token against the given set of matches; emits an error if
  /// it can't find a match, but still consumes the token.
  ///
  /// This function's primary use is for generating diagnostics; the caller will
  /// still need to match on the resulting [`Token`] to extract its contents.
  #[track_caller]
  pub fn one_of(
    &mut self,
    fcx: &FileCtx,
    lexemes: &[Lexeme],
  ) -> Option<Token<'lex>> {
    let next = self.next()?;
    for &lex in lexemes {
      if next.is(lex) {
        return Some(next);
      }
    }

    ReportCtx::current().builtins().expected_one_of(
      fcx,
      self.spec,
      lexemes.iter().copied(),
      next,
      next,
    );

    None
  }

  /// Like [`Cursor::one_of()`], but does not skip over the token.
  pub fn peek_one_of(
    &self,
    fcx: &FileCtx,
    lexemes: &[Lexeme],
  ) -> Option<Token<'lex>> {
    let mut copy = *self;
    copy.one_of(fcx, lexemes)
  }
}

impl fmt::Debug for Cursor<'_> {
  fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
    let mut copy = *self;
    copy.cursor = 0;

    let mut list = f.debug_list();
    for (i, tok) in copy.enumerate() {
      struct Selectable<'a>(Token<'a>, bool);
      impl fmt::Debug for Selectable<'_> {
        fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
          if self.1 {
            f.write_str("* ")?;
          } else {
            f.write_str("x ")?;
          }
          fmt::Debug::fmt(&self.0, f)
        }
      }

      list.entry(&Selectable(tok, i == self.cursor));
    }
    list.finish()
  }
}

impl<'lex> Iterator for Cursor<'lex> {
  type Item = Token<'lex>;
  fn next(&mut self) -> Option<Self::Item> {
    let tok = self.toks.get(self.cursor)?;
    let next = match &tok.kind {
      Kind::Eof => {
        self.cursor += 1;
        Token::Eof(tok.span)
      }

      Kind::Unexpected => {
        self.cursor += 1;
        Token::Unexpected(tok.span)
      }

      Kind::Keyword => {
        self.cursor += 1;
        Token::Keyword(tok.lexeme.unwrap(), tok.span)
      }

      Kind::Ident { .. } => {
        self.cursor += 1;
        Token::Ident(Ident { tok })
      }

      Kind::Quoted { .. } => {
        self.cursor += 1;
        Token::Quoted(Quoted { tok })
      }

      Kind::Number { .. } => {
        self.cursor += 1;
        Token::Number(Number { tok })
      }

      Kind::Open { offset_to_close } => {
        let open_idx = self.cursor;
        let close_idx = open_idx + (*offset_to_close as usize);
        self.cursor = close_idx + 1;

        let close = &self.toks[close_idx];
        let &Kind::Close { .. } = &close.kind else {
          panic!("rt::Kind::Open did not point to an rt:Kind::Close; this is a bug");
        };

        Token::Delimited {
          open: tok.span,
          close: close.span,
          lexeme: tok.lexeme.unwrap(),
          contents: Cursor {
            spec: self.spec,
            toks: &self.toks[open_idx + 1..close_idx],
            cursor: 0,
          },
        }
      }

      Kind::Close { .. } => {
        panic!(
          "stray closing delimiter {:?} in token stream; this is a bug",
          tok.span
        )
      }
    };

    Some(next)
  }
}
