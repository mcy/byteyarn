use std::fmt;

use byteyarn::yarn;
use byteyarn::YarnBox;

use crate::file::FileCtx;
use crate::file::Span;
use crate::file::Spanned;
use crate::lexer::rt;
use crate::lexer::rt::Kind;
use crate::lexer::spec::Lexeme;
use crate::lexer::spec::Spec;

mod stream;

pub use stream::Cursor;
pub use stream::TokenStream;

#[cfg(doc)]
use crate::lexer::spec::EscapeRule;

/// A token generated by a lexing operation.
#[derive(Copy, Clone)]
pub enum Token<'lex> {
  Eof(Span),
  Unexpected(Span),
  Ident(Ident<'lex>),
  Quoted(Quoted<'lex>),
  Number(Number<'lex>),
  Keyword(Lexeme, Span),
  Delimited {
    open: Span,
    close: Span,
    lexeme: Lexeme,
    contents: Cursor<'lex>,
  },
}

impl<'lex> Token<'lex> {
  pub fn is(self, lexeme: Lexeme) -> bool {
    match self {
      Token::Unexpected(..) => false,
      Token::Eof(..) => lexeme == Lexeme::eof(),
      Token::Ident(tok) => tok.is(lexeme),
      Token::Quoted(tok) => tok.is(lexeme),
      Token::Number(tok) => tok.is(lexeme),
      Token::Keyword(this, _) => this == lexeme,
      Token::Delimited { lexeme: this, .. } => this == lexeme,
    }
  }

  pub fn eof(self) -> Option<Span> {
    match self {
      Self::Eof(span) => Some(span),
      _ => None,
    }
  }

  pub fn keyword(self) -> Option<Span> {
    match self {
      Self::Keyword(_, span) => Some(span),
      _ => None,
    }
  }

  pub fn ident(self) -> Option<Ident<'lex>> {
    match self {
      Self::Ident(tok) => Some(tok),
      _ => None,
    }
  }

  pub fn quoted(self) -> Option<Quoted<'lex>> {
    match self {
      Self::Quoted(tok) => Some(tok),
      _ => None,
    }
  }

  pub fn number(self) -> Option<Number<'lex>> {
    match self {
      Self::Number(tok) => Some(tok),
      _ => None,
    }
  }

  pub fn delimited(self) -> Option<Cursor<'lex>> {
    match self {
      Self::Delimited { contents, .. } => Some(contents),
      _ => None,
    }
  }
}

impl fmt::Debug for Token<'_> {
  fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
    match self {
      Self::Eof(span) => write!(f, "Eof({span:?})"),
      Self::Unexpected(span) => write!(f, "Unexpected({span:?})"),
      Self::Ident(tok) => fmt::Debug::fmt(tok, f),
      Self::Quoted(tok) => fmt::Debug::fmt(tok, f),
      Self::Number(tok) => fmt::Debug::fmt(tok, f),
      Self::Keyword(_, span) => write!(f, "Keyword({span:?})"),
      Self::Delimited {
        open,
        close,
        contents,
        lexeme: _,
      } => f
        .debug_struct("Delimited")
        .field("delimiters", &(open, close))
        .field("contents", &contents)
        .finish(),
    }
  }
}

impl Spanned for Token<'_> {
  fn span(&self, fcx: &FileCtx) -> Span {
    match *self {
      Token::Eof(span) | Token::Keyword(_, span) | Token::Unexpected(span) => {
        span
      }
      Token::Ident(tok) => tok.span(fcx),
      Token::Quoted(tok) => tok.span(fcx),
      Token::Number(tok) => tok.span(fcx),
      Token::Delimited { open, close, .. } => fcx.join([open, close]),
    }
  }
}

/// Something that looks enough like a [`Token`] that it could be used for
/// diagnostics.
pub enum Tokenish<'lex> {
  Literal(&'lex str),
  Lexeme(Lexeme),
  Token(Token<'lex>),
}

impl Tokenish<'_> {
  /// Converts this tokenish into a string that can be used in a diagnostic.
  pub(crate) fn for_user_diagnostic<'a>(
    &'a self,
    spec: &'a Spec,
    fcx: &FileCtx,
  ) -> YarnBox<'a, str> {
    use crate::lexer::stringify::lexeme_to_string;
    match self {
      Self::Literal(lit) => yarn!("`{lit}`"),
      &Self::Lexeme(lex) => lexeme_to_string(spec, lex),
      Self::Token(tok) => match tok {
        Token::Ident(Ident { tok })
        | Token::Number(Number { tok })
        | Token::Quoted(Quoted { tok }) => {
          lexeme_to_string(spec, tok.lexeme.unwrap())
        }
        Token::Eof(..) => yarn!("<eof>"),
        &Token::Keyword(lex, _) => lexeme_to_string(spec, lex),
        &Token::Delimited { lexeme, .. } => lexeme_to_string(spec, lexeme),
        Token::Unexpected(span) => yarn!("`{}`", span.text(fcx)),
      },
    }
  }
}

impl<'lex, S: AsRef<str> + ?Sized> From<&'lex S> for Tokenish<'lex> {
  fn from(value: &'lex S) -> Self {
    Self::Literal(value.as_ref())
  }
}

impl From<Lexeme> for Tokenish<'_> {
  fn from(value: Lexeme) -> Self {
    Self::Lexeme(value)
  }
}

impl<'lex> From<Token<'lex>> for Tokenish<'lex> {
  fn from(value: Token<'lex>) -> Self {
    Self::Token(value)
  }
}

/// A identifier, i.e., a self-delimiting word like `foo` or `黒猫`.
#[derive(Copy, Clone)]
pub struct Ident<'lex> {
  tok: &'lex rt::Token,
}

impl fmt::Debug for Ident<'_> {
  fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
    if self.prefix().is_none() && self.suffix().is_none() {
      return write!(f, "Ident({:?})", self.tok.span);
    }

    let mut f = f.debug_struct("Ident");
    f.field("span", &self.tok.span).field("name", &self.name());

    if let Some(prefix) = self.prefix() {
      f.field("prefix", &prefix);
    }

    if let Some(suffix) = self.suffix() {
      f.field("suffix", &suffix);
    }

    f.finish()
  }
}

impl<'lex> Ident<'lex> {
  /// Returns whether this token came from a particular [`Lexeme`].
  pub fn is(self, lexeme: Lexeme) -> bool {
    self.tok.lexeme == Some(lexeme)
  }

  /// Returns this token's name span.
  pub fn name(self) -> Span {
    match &self.tok.kind {
      &Kind::Ident(name) => name,
      _ => panic!("non-rt::Kind::Ident inside of Ident"),
    }
  }

  /// Returns this token's prefix sigil span.
  pub fn prefix(self) -> Option<Span> {
    self.tok.prefix
  }

  /// Checks whether this identifier has a particular prefix.
  pub fn has_prefix(&self, fcx: &FileCtx, expected: &str) -> bool {
    self.prefix().is_some_and(|s| s.text(fcx) == expected)
  }

  /// Returns this token's suffix sigil span.
  pub fn suffix(&self) -> Option<Span> {
    self.tok.suffix
  }

  /// Checks whether this identifier has a particular prefix.
  pub fn has_suffix(&self, fcx: &FileCtx, expected: &str) -> bool {
    self.suffix().is_some_and(|s| s.text(fcx) == expected)
  }
}

impl Spanned for Ident<'_> {
  fn span(&self, _fcx: &FileCtx) -> Span {
    self.tok.span
  }
}

/// An integer literal.
///
/// Casing of digits, and underscores between them, are currently discarded.
#[derive(Copy, Clone)]
pub struct Number<'lex> {
  tok: &'lex rt::Token,
}

impl fmt::Debug for Number<'_> {
  fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
    let mut f = f.debug_struct("Number");
    f.field("span", &self.tok.span)
      .field("radix", &self.radix())
      .field("digits", &self.digit_slice());

    if let Some(prefix) = self.prefix() {
      f.field("prefix", &prefix);
    }

    if let Some(suffix) = self.suffix() {
      f.field("suffix", &suffix);
    }

    if let Some(exponent) = self.exponent() {
      f.field("exponent", &exponent);
    }

    f.finish()
  }
}

/// An exponent from a [`Number`] literal.
pub struct Exponent {
  /// The sign on the exponent (a `+` or a `-`).
  pub sign: Option<Span>,
  /// The exponent's span, not including the sign.
  pub span: Span,
}

impl fmt::Debug for Exponent {
  fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
    let mut f = f.debug_struct("Exponent");
    if let Some(sign) = &self.sign {
      f.field("sign", sign);
    }
    f.field("span", &self.span).finish()
  }
}

impl<'lex> Number<'lex> {
  /// Returns whether this token came from a particular [`Lexeme`].
  pub fn is(self, lexeme: Lexeme) -> bool {
    self.tok.lexeme == Some(lexeme)
  }

  /// Returns the radix (or base) that this number's digits were parsed from.
  pub fn radix(self) -> u8 {
    match &self.tok.kind {
      &Kind::Number { radix, .. } => radix,
      _ => panic!("non-rt::Kind::Number inside of Number"),
    }
  }

  /// Returns the `.`-separated digit chunks of this number.
  pub fn digit_blocks(self) -> impl Iterator<Item = Span> + 'lex {
    self.digit_slice().iter().copied()
  }

  fn digit_slice(self) -> &'lex [Span] {
    match &self.tok.kind {
      Kind::Number { digit_blocks, .. } => digit_blocks,
      _ => panic!("non-rt::Kind::Number inside of Number"),
    }
  }

  /// Returns the exponent of this number, if it has one.
  pub fn exponent(self) -> Option<Exponent> {
    let Kind::Number { exponent, .. } = &self.tok.kind else {
      panic!("non-rt::Kind::Number inside of Number")
    };

    exponent
      .as_ref()
      .map(|&(sign, span)| Exponent { sign, span })
  }

  /// Returns this token's prefix sigil span.
  pub fn prefix(self) -> Option<Span> {
    self.tok.prefix
  }

  /// Checks whether this identifier has a particular prefix.
  pub fn has_prefix(&self, fcx: &FileCtx, expected: &str) -> bool {
    self.prefix().is_some_and(|s| s.text(fcx) == expected)
  }

  /// Returns this token's suffix sigil span.
  pub fn suffix(&self) -> Option<Span> {
    self.tok.suffix
  }

  /// Checks whether this identifier has a particular prefix.
  pub fn has_suffix(&self, fcx: &FileCtx, expected: &str) -> bool {
    self.suffix().is_some_and(|s| s.text(fcx) == expected)
  }
}

impl Spanned for Number<'_> {
  fn span(&self, _fcx: &FileCtx) -> Span {
    self.tok.span
  }
}

/// A quoted literal.
#[derive(Copy, Clone)]
pub struct Quoted<'lex> {
  tok: &'lex rt::Token,
}

#[derive(Copy, Clone, Debug)]
pub enum Content {
  Lit(Span),
  Esc(Span, u32),
}

impl fmt::Debug for Quoted<'_> {
  fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
    let mut f = f.debug_struct("Quoted");
    f.field("span", &self.tok.span)
      .field("delimiters", &self.delimiters())
      .field("content", &self.content_slice());

    if let Some(prefix) = self.prefix() {
      f.field("prefix", &prefix);
    }

    if let Some(suffix) = self.suffix() {
      f.field("suffix", &suffix);
    }

    f.finish()
  }
}

impl<'lex> Quoted<'lex> {
  /// Returns whether this token came from a particular [`Lexeme`].
  pub fn is(self, lexeme: Lexeme) -> bool {
    self.tok.lexeme == Some(lexeme)
  }

  /// Returns this token's open delimiter.
  pub fn open(self) -> Span {
    self.delimiters().0
  }

  /// Returns this token's close delimiter.
  pub fn close(self) -> Span {
    self.delimiters().0
  }

  /// Returns this token's quote delimiters.
  pub fn delimiters(self) -> (Span, Span) {
    match &self.tok.kind {
      &Kind::Quoted { open, close, .. } => (open, close),
      _ => panic!("non-rt::Kind::Quoted inside of Quoted"),
    }
  }

  /// Returns the raw content of this token.
  ///
  /// There are two kinds of content: either a literal span of Unicode scalars
  /// (represented as a [`Span`] pointing to those characters) or a single
  /// escaped "code", which is an arbitrary `u32` value produced by a callback
  /// in an [`EscapeRule`].
  ///
  /// It is up to the user of the library to decode these two content types into
  /// strings. This is one way it could be done for a Unicode string (of
  /// unspecified target encoding, although the compiler encoding is UTF-8
  /// here):
  ///
  /// ```
  /// # use ilex::{Content, Quoted};
  /// fn decode_unicode(q: Quoted, fcx: &ilex::FileCtx) -> String {
  ///   let mut out = String::new();
  ///   for chunk in q.raw_content() {
  ///     match chunk {
  ///       Content::Lit(span) => out.push_str(span.text(fcx)),
  ///       Content::Esc(_, code) => out.push(char::from_u32(code).unwrap()),
  ///     }
  ///   }
  ///   out
  /// }
  /// ```
  pub fn raw_content(self) -> impl Iterator<Item = Content> + 'lex {
    self.content_slice().iter().copied()
  }

  fn content_slice(self) -> &'lex [Content] {
    match &self.tok.kind {
      Kind::Quoted { content, .. } => content,
      _ => panic!("non-rt::Kind::Quoted inside of Quoted"),
    }
  }

  /// Returns this token's prefix sigil span.
  pub fn prefix(self) -> Option<Span> {
    self.tok.prefix
  }

  /// Checks whether this identifier has a particular prefix.
  pub fn has_prefix(&self, fcx: &FileCtx, expected: &str) -> bool {
    self.prefix().is_some_and(|s| s.text(fcx) == expected)
  }

  /// Returns this token's suffix sigil span.
  pub fn suffix(&self) -> Option<Span> {
    self.tok.suffix
  }

  /// Checks whether this identifier has a particular prefix.
  pub fn has_suffix(&self, fcx: &FileCtx, expected: &str) -> bool {
    self.suffix().is_some_and(|s| s.text(fcx) == expected)
  }
}

impl Spanned for Quoted<'_> {
  fn span(&self, _fcx: &FileCtx) -> Span {
    self.tok.span
  }
}
